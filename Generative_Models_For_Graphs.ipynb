{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generative_Models_For_Graphs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "16a922de35c14453967f8b754c137f6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4ae51b34cc684fbb80415ed291438fed",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9eebd2acf9b7417a8373ab2eca24e06f",
              "IPY_MODEL_1dc321393c1a44ad9e6498921e304d2d"
            ]
          }
        },
        "4ae51b34cc684fbb80415ed291438fed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9eebd2acf9b7417a8373ab2eca24e06f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2e393cf3d669453790a02c06bbedf59a",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 37972,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 37972,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_54dc038ff3774fe0b7e75ded2a754464"
          }
        },
        "1dc321393c1a44ad9e6498921e304d2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bf2a0790ef2949868f1b54cf0419cd1f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 37.1k/37.1k [00:00&lt;00:00, 122kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f0919f69501546e6902a4a78b4c890a9"
          }
        },
        "2e393cf3d669453790a02c06bbedf59a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "54dc038ff3774fe0b7e75ded2a754464": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bf2a0790ef2949868f1b54cf0419cd1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f0919f69501546e6902a4a78b4c890a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3O-6S2-NvBQs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "c5dd25a1-bd13-431e-eca2-1996048454e6"
      },
      "source": [
        "#Installing Deep Graph Library\n",
        "!pip install dgl\n",
        "import dgl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dgl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/b4/84e4ebd70ef3985181ef5d2d2a366a45af0e3cd18d249fb212ac03f683cf/dgl-0.4.3.post2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from dgl) (2.23.0)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.6/dist-packages (from dgl) (2.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from dgl) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from dgl) (1.18.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl) (2020.6.20)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.1->dgl) (4.4.2)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-0.4.3.post2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUVPKTa8w3JY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function for the inference\n",
        "\"\"\"Forward at inference time.\n",
        "        It generates graphs on the fly.\"\"\"\n",
        "'''It checks if the nodes created are within v_max and in loop adds the nodes,edges and choosing the destination'''\n",
        "def forward_inference(self):\n",
        "    stop = self.add_node_and_update()\n",
        "    while (not stop) and (self.g.number_of_nodes() < self.v_max + 1):\n",
        "        num_trials = 0\n",
        "        to_add_edge = self.add_edge_or_not()\n",
        "        while to_add_edge and (num_trials < self.g.number_of_nodes() - 1):\n",
        "            self.choose_dest_and_update()\n",
        "            num_trials += 1\n",
        "            to_add_edge = self.add_edge_or_not()\n",
        "        stop = self.add_node_and_update()\n",
        "\n",
        "    return self.g"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ms0ldP1IOC7V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function for the training\n",
        "'''Forward at training time. It records the probability\n",
        "        of generating a ground truth graph following the actions'''\n",
        "def forward_train(self, actions):\n",
        "    \"\"\"\n",
        "    - actions: list\n",
        "        - Contains a_1, ..., a_T described above\n",
        "    - self.prepare_for_train()\n",
        "        - Initializes self.action_step to be 0, which will get\n",
        "          incremented by 1 every time it is called.\n",
        "        - Initializes objects recording log p(a_t|a_1,...a_{t-1})\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    - self.get_log_prob(): log p(a_1, ..., a_T)\n",
        "    \"\"\"\n",
        "    self.prepare_for_train()\n",
        "    '''action_step is given as the input'''\n",
        "\n",
        "    stop = self.add_node_and_update(a=actions[self.action_step])\n",
        "    while not stop:\n",
        "        to_add_edge = self.add_edge_or_not(a=actions[self.action_step])\n",
        "        while to_add_edge:\n",
        "            self.choose_dest_and_update(a=actions[self.action_step])\n",
        "            to_add_edge = self.add_edge_or_not(a=actions[self.action_step])\n",
        "        stop = self.add_node_and_update(a=actions[self.action_step])\n",
        "\n",
        "    return self.get_log_prob()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PK6LiAJUb3pH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Implementing the Graph Embedding as GraphEmbed class\n",
        "import torch\n",
        "\n",
        "\n",
        "class GraphEmbed(nn.Module):\n",
        "    def __init__(self, node_hidden_size):\n",
        "        super(GraphEmbed, self).__init__()\n",
        "\n",
        "        # Setting from the paper\n",
        "        # graph_hidden_size is set as twice the node_hidden_size\n",
        "        self.graph_hidden_size = 2 * node_hidden_size\n",
        "\n",
        "        # Embed graphs\n",
        "        # node gating- how much the overall graph embedding attends on each node\n",
        "        self.node_gating = nn.Sequential(\n",
        "            nn.Linear(node_hidden_size, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        # maps the node embeddings to the space of graph embeddings\n",
        "        self.node_to_graph = nn.Linear(node_hidden_size,\n",
        "                                       self.graph_hidden_size)\n",
        "\n",
        "    def forward(self, g):\n",
        "        if g.number_of_nodes() == 0:\n",
        "            return torch.zeros(1, self.graph_hidden_size)\n",
        "        else:\n",
        "            # Node features are stored as hv in ndata.\n",
        "            hvs = g.ndata['hv']\n",
        "            return (self.node_gating(hvs) *\n",
        "                    self.node_to_graph(hvs)).sum(0, keepdim=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHu1t26IcESk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Implementing the Graph Propagation as GraphProp class\n",
        "from functools import partial\n",
        "\n",
        "class GraphProp(nn.Module):\n",
        "    def __init__(self, num_prop_rounds, node_hidden_size):\n",
        "        super(GraphProp, self).__init__()\n",
        "\n",
        "        self.num_prop_rounds = num_prop_rounds\n",
        "\n",
        "        # Setting from the paper, graph_hidden_size is set as twice the node_hidden_size\n",
        "        self.node_activation_hidden_size = 2 * node_hidden_size\n",
        "\n",
        "        message_funcs = []\n",
        "        node_update_funcs = []\n",
        "        self.reduce_funcs = []\n",
        "\n",
        "        # Number of times the propagation done\n",
        "        for t in range(num_prop_rounds):\n",
        "            # input being [hv, hu, xuv]\n",
        "            # message and reduce - similar to the graph convolution\n",
        "            message_funcs.append(nn.Linear(2 * node_hidden_size + 1,\n",
        "                                           self.node_activation_hidden_size))\n",
        "\n",
        "            self.reduce_funcs.append(partial(self.dgmg_reduce, round=t))\n",
        "            #updating the graph node with previous h and activation vectors\n",
        "            node_update_funcs.append(\n",
        "                nn.GRUCell(self.node_activation_hidden_size,\n",
        "                           node_hidden_size))\n",
        "\n",
        "        self.message_funcs = nn.ModuleList(message_funcs)\n",
        "        self.node_update_funcs = nn.ModuleList(node_update_funcs)\n",
        "\n",
        "    # message function defined\n",
        "    def dgmg_msg(self, edges):\n",
        "        \"\"\"For an edge u->v, return concat([h_u, x_uv])\"\"\"\n",
        "        return {'m': torch.cat([edges.src['hv'],\n",
        "                                edges.data['he']],\n",
        "                               dim=1)}\n",
        "\n",
        "    # reduce function defined\n",
        "    def dgmg_reduce(self, nodes, round):\n",
        "        hv_old = nodes.data['hv']\n",
        "        m = nodes.mailbox['m']\n",
        "        message = torch.cat([\n",
        "            hv_old.unsqueeze(1).expand(-1, m.size(1), -1), m], dim=2)\n",
        "        node_activation = (self.message_funcs[round](message)).sum(1)\n",
        "\n",
        "        return {'a': node_activation}\n",
        "\n",
        "    # forward function for the graph propagation\n",
        "    def forward(self, g):\n",
        "        if g.number_of_edges() > 0:\n",
        "            for t in range(self.num_prop_rounds):\n",
        "                g.update_all(message_func=self.dgmg_msg,\n",
        "                             reduce_func=self.reduce_funcs[t])\n",
        "                g.ndata['hv'] = self.node_update_funcs[t](\n",
        "                     g.ndata['a'], g.ndata['hv'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_hgJA-X_SNH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "from torch.distributions import Bernoulli\n",
        "\n",
        "def bernoulli_action_log_prob(logit, action):\n",
        "    \"\"\"Calculate the log p of an action with respect to a Bernoulli\n",
        "    distribution. Use logit rather than prob for numerical stability.\"\"\"\n",
        "    if action == 0:\n",
        "        return F.logsigmoid(-logit)\n",
        "    else:\n",
        "        return F.logsigmoid(logit)\n",
        "\n",
        "#Defining the AddNode class\n",
        "class AddNode(nn.Module):\n",
        "    def __init__(self, graph_embed_func, node_hidden_size):\n",
        "        super(AddNode, self).__init__()\n",
        "\n",
        "        # graph embedding\n",
        "        self.graph_op = {'embed': graph_embed_func}\n",
        "\n",
        "        self.stop = 1\n",
        "        self.add_node = nn.Linear(graph_embed_func.graph_hidden_size, 1)\n",
        "\n",
        "        # If to add a node, initialize its hv\n",
        "        self.node_type_embed = nn.Embedding(1, node_hidden_size)\n",
        "        # Weight matrix initialize_hv\n",
        "        self.initialize_hv = nn.Linear(node_hidden_size + \\\n",
        "                                       graph_embed_func.graph_hidden_size,\n",
        "                                       node_hidden_size)\n",
        "\n",
        "        self.init_node_activation = torch.zeros(1, 2 * node_hidden_size)\n",
        "\n",
        "    def _initialize_node_repr(self, g, node_type, graph_embed):\n",
        "        \"\"\"Whenver a node is added, initialize its representation.\"\"\"\n",
        "        num_nodes = g.number_of_nodes()\n",
        "        # node type and graph embedding passed as arguments\n",
        "        hv_init = self.initialize_hv(\n",
        "            torch.cat([\n",
        "                self.node_type_embed(torch.LongTensor([node_type])),\n",
        "                graph_embed], dim=1))\n",
        "        g.nodes[num_nodes - 1].data['hv'] = hv_init\n",
        "        g.nodes[num_nodes - 1].data['a'] = self.init_node_activation\n",
        "\n",
        "    def prepare_training(self):\n",
        "        self.log_prob = []\n",
        "\n",
        "    def forward(self, g, action=None):\n",
        "        graph_embed = self.graph_op['embed'](g)\n",
        "\n",
        "        logit = self.add_node(graph_embed)\n",
        "        prob = torch.sigmoid(logit)\n",
        "\n",
        "        # during inference\n",
        "        if not self.training:\n",
        "            action = Bernoulli(prob).sample().item()\n",
        "        stop = bool(action == self.stop)\n",
        "\n",
        "        # intializing node representation\n",
        "        if not stop:\n",
        "            g.add_nodes(1)\n",
        "            self._initialize_node_repr(g, action, graph_embed)\n",
        "\n",
        "        # during training\n",
        "        if self.training:\n",
        "            sample_log_prob = bernoulli_action_log_prob(logit, action)\n",
        "\n",
        "            self.log_prob.append(sample_log_prob)\n",
        "\n",
        "        return stop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMAYxF38AmvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Defining the AddEdge class\n",
        "class AddEdge(nn.Module):\n",
        "    def __init__(self, graph_embed_func, node_hidden_size):\n",
        "        super(AddEdge, self).__init__()\n",
        "\n",
        "        self.graph_op = {'embed': graph_embed_func}\n",
        "        # Weight matrix add_edge\n",
        "        self.add_edge = nn.Linear(graph_embed_func.graph_hidden_size + \\\n",
        "                                  node_hidden_size, 1)\n",
        "\n",
        "    def prepare_training(self):\n",
        "        self.log_prob = []\n",
        "\n",
        "    def forward(self, g, action=None):\n",
        "        graph_embed = self.graph_op['embed'](g)\n",
        "        src_embed = g.nodes[g.number_of_nodes() - 1].data['hv']\n",
        "        \n",
        "        # graph and source node embedding passed as arguments\n",
        "        logit = self.add_edge(torch.cat(\n",
        "            [graph_embed, src_embed], dim=1))\n",
        "        prob = torch.sigmoid(logit)\n",
        "\n",
        "        if self.training:\n",
        "            sample_log_prob = bernoulli_action_log_prob(logit, action)\n",
        "            self.log_prob.append(sample_log_prob)\n",
        "        else:\n",
        "            action = Bernoulli(prob).sample().item()\n",
        "\n",
        "        to_add_edge = bool(action == 0)\n",
        "        return to_add_edge"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6flmiBaCc8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Defining the ChooseDestAndUpdate class\n",
        "from torch.distributions import Categorical\n",
        "\n",
        "class ChooseDestAndUpdate(nn.Module):\n",
        "    def __init__(self, graph_prop_func, node_hidden_size):\n",
        "        super(ChooseDestAndUpdate, self).__init__()\n",
        "\n",
        "        self.graph_op = {'prop': graph_prop_func}\n",
        "        # Weight matrix choose_dest\n",
        "        self.choose_dest = nn.Linear(2 * node_hidden_size, 1)\n",
        "\n",
        "    def _initialize_edge_repr(self, g, src_list, dest_list):\n",
        "        # For untyped edges, only add 1 to indicate its existence.\n",
        "        # For multiple edge types, use a one-hot representation\n",
        "        # or an embedding module.\n",
        "        edge_repr = torch.ones(len(src_list), 1)\n",
        "        g.edges[src_list, dest_list].data['he'] = edge_repr\n",
        "\n",
        "    def prepare_training(self):\n",
        "        self.log_prob = []\n",
        "\n",
        "    def forward(self, g, dest):\n",
        "        src = g.number_of_nodes() - 1\n",
        "        possible_dests = range(src)\n",
        "\n",
        "        src_embed_expand = g.nodes[src].data['hv'].expand(src, -1)\n",
        "        possible_dests_embed = g.nodes[possible_dests].data['hv']\n",
        "\n",
        "        # possible destination and source embeddings as arguments\n",
        "        dests_scores = self.choose_dest(\n",
        "            torch.cat([possible_dests_embed,\n",
        "                       src_embed_expand], dim=1)).view(1, -1)\n",
        "        dests_probs = F.softmax(dests_scores, dim=1)\n",
        "\n",
        "        if not self.training:\n",
        "            dest = Categorical(dests_probs).sample().item()\n",
        "\n",
        "        if not g.has_edge_between(src, dest):\n",
        "            # For undirected graphs, add edges for both directions\n",
        "            # so that you can perform graph propagation.\n",
        "            src_list = [src, dest]\n",
        "            dest_list = [dest, src]\n",
        "\n",
        "            g.add_edges(src_list, dest_list)\n",
        "            # intializing the edge representation\n",
        "            self._initialize_edge_repr(g, src_list, dest_list)\n",
        "\n",
        "            self.graph_op['prop'](g)\n",
        "\n",
        "        # destination score appended\n",
        "        if self.training:\n",
        "            if dests_probs.nelement() > 1:\n",
        "                self.log_prob.append(\n",
        "                    F.log_softmax(dests_scores, dim=1)[:, dest: dest + 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dn4iGbjhCeXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Defining the DGMG class\n",
        "class DGMG(DGMGSkeleton):\n",
        "    def __init__(self, v_max, node_hidden_size,\n",
        "                 num_prop_rounds):\n",
        "        super(DGMG, self).__init__(v_max)\n",
        "\n",
        "        # Graph embedding module\n",
        "        self.graph_embed = GraphEmbed(node_hidden_size)\n",
        "\n",
        "        # Graph propagation module\n",
        "        self.graph_prop = GraphProp(num_prop_rounds,\n",
        "                                    node_hidden_size)\n",
        "\n",
        "        # Actions\n",
        "        self.add_node_agent = AddNode(\n",
        "            self.graph_embed, node_hidden_size)\n",
        "        self.add_edge_agent = AddEdge(\n",
        "            self.graph_embed, node_hidden_size)\n",
        "        self.choose_dest_agent = ChooseDestAndUpdate(\n",
        "            self.graph_prop, node_hidden_size)\n",
        "\n",
        "        # Forward functions\n",
        "        self.forward_train = partial(forward_train, self=self)\n",
        "        self.forward_inference = partial(forward_inference, self=self)\n",
        "\n",
        "    @property\n",
        "    def action_step(self):\n",
        "        old_step_count = self.step_count\n",
        "        self.step_count += 1\n",
        "\n",
        "        return old_step_count\n",
        "\n",
        "    def prepare_for_train(self):\n",
        "        self.step_count = 0\n",
        "\n",
        "        self.add_node_agent.prepare_training()\n",
        "        self.add_edge_agent.prepare_training()\n",
        "        self.choose_dest_agent.prepare_training()\n",
        "\n",
        "    def add_node_and_update(self, a=None):\n",
        "        \"\"\"Decide if to add a new node.\n",
        "        If a new node should be added, update the graph.\"\"\"\n",
        "\n",
        "        return self.add_node_agent(self.g, a)\n",
        "\n",
        "    def add_edge_or_not(self, a=None):\n",
        "        \"\"\"Decide if a new edge should be added.\"\"\"\n",
        "\n",
        "        return self.add_edge_agent(self.g, a)\n",
        "\n",
        "    def choose_dest_and_update(self, a=None):\n",
        "        \"\"\"Choose destination and connect it to the latest node.\n",
        "        Add edges for both directions and update the graph.\"\"\"\n",
        "\n",
        "        self.choose_dest_agent(self.g, a)\n",
        "\n",
        "    def get_log_prob(self):\n",
        "        add_node_log_p = torch.cat(self.add_node_agent.log_prob).sum()\n",
        "        add_edge_log_p = torch.cat(self.add_edge_agent.log_prob).sum()\n",
        "        choose_dest_log_p = torch.cat(self.choose_dest_agent.log_prob).sum()\n",
        "        return add_node_log_p + add_edge_log_p + choose_dest_log_p\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tAANMPLCvCV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "16a922de35c14453967f8b754c137f6b",
            "4ae51b34cc684fbb80415ed291438fed",
            "9eebd2acf9b7417a8373ab2eca24e06f",
            "1dc321393c1a44ad9e6498921e304d2d",
            "2e393cf3d669453790a02c06bbedf59a",
            "54dc038ff3774fe0b7e75ded2a754464",
            "bf2a0790ef2949868f1b54cf0419cd1f",
            "f0919f69501546e6902a4a78b4c890a9"
          ]
        },
        "outputId": "7f096af0-bfd6-4b47-d3ed-6c7202ba789e"
      },
      "source": [
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "# Downloading a pre-trained model state dict for generating cycles with 10-20 nodes.\n",
        "state_dict = model_zoo.load_url('https://data.dgl.ai/model/dgmg_cycles-5a0c40be.pth')\n",
        "model = DGMG(v_max=20, node_hidden_size=16, num_prop_rounds=2)\n",
        "model.load_state_dict(state_dict)\n",
        "model.eval()\n",
        "\n",
        "def is_valid(g):\n",
        "    # Check if g is a cycle having 10-20 nodes.\n",
        "    # Checking the node number for the previous and the next nodes\n",
        "    def _get_previous(i, v_max):\n",
        "        # if i=0, check if the previous node is v_max\n",
        "        if i == 0:\n",
        "            return v_max\n",
        "        else:\n",
        "            return i - 1\n",
        "\n",
        "    def _get_next(i, v_max):\n",
        "        # if i=v_max, check if the next node is 0\n",
        "        if i == v_max:\n",
        "            return 0\n",
        "        else:\n",
        "            return i + 1\n",
        "\n",
        "    size = g.number_of_nodes()\n",
        "\n",
        "    # checking if the no of nodes is within the range\n",
        "    if size < 10 or size > 20:\n",
        "        return False\n",
        "\n",
        "    for node in range(size):\n",
        "        neighbors = g.successors(node)\n",
        "\n",
        "        if len(neighbors) != 2:\n",
        "            return False\n",
        "\n",
        "        if _get_previous(node, size - 1) not in neighbors:\n",
        "            return False\n",
        "\n",
        "        if _get_next(node, size - 1) not in neighbors:\n",
        "            return False\n",
        "\n",
        "    return True\n",
        "\n",
        "num_valid = 0\n",
        "for i in range(100):\n",
        "    g = model()\n",
        "    num_valid += is_valid(g)\n",
        "\n",
        "del model\n",
        "print('Among 100 graphs generated, {}% are valid.'.format(num_valid))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://data.dgl.ai/model/dgmg_cycles-5a0c40be.pth\" to /root/.cache/torch/checkpoints/dgmg_cycles-5a0c40be.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "16a922de35c14453967f8b754c137f6b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=37972.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Among 100 graphs generated, 94% are valid.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}